Why does double DQN work better?

• Double DQN decouples selection from evaluation.

• Selection using DQN: $a^* = \text{argmax}_a Q(s_{t+1}, a; \mathbf{w})$.

• Evaluation using target network: $y_t = r_t + \gamma \cdot Q(s_{t+1}, a^*; \mathbf{w}^-)$.

• Double DQN alleviates overestimation:

$Q(s_{t+1}, a^*; \mathbf{w}^-) \leq \max_a Q(s_{t+1}, a; \mathbf{w}^-)$

Estimation by             Estimation by
Double DQN               target network