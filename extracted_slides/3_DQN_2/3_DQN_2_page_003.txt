TD Learning for DQN

• In RL, bootstrapping means "using an estimated value in the update step for the same kind of estimated value".

• Use a transition, $(s_t, a_t, r_t, s_{t+1})$, to update $\mathbf{w}$.

  • TD target:  $y_t = r_t + \gamma \cdot \max_a Q(s_{t+1}, a; \mathbf{w})$.

  • TD error:   $\delta_t = Q(s_t, a_t; \mathbf{w}) - y_t$.

  • SGD:  $\mathbf{w} \leftarrow \mathbf{w} - \alpha \cdot \delta_t \cdot \frac{\partial Q(s_t,a_t;\mathbf{w})}{\partial \mathbf{w}}$.