Policy Gradient

Policy gradient: Derivative of state-value function $V(s; \boldsymbol{\theta})$ w.r.t. $\boldsymbol{\theta}$.

â€¢ Recall that $\frac{\partial \log \pi(a_t \vert s_t, \boldsymbol{\theta})}{\partial \boldsymbol{\theta}} \cdot Q_\pi(s_t, a_t)$ is approximate policy gradient.