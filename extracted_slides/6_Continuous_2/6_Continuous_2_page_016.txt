Updating Policy Network by DPG

• Goal: Increasing $q(s, a; \mathbf{w})$, where $a = \pi(s; \boldsymbol{\theta})$.
• DPG: $\mathbf{g} = \frac{\partial q(s,\pi(s;\boldsymbol{\theta});\mathbf{w})}{\partial \boldsymbol{\theta}} = \frac{\partial a}{\partial \boldsymbol{\theta}} \cdot \frac{\partial q(s,a;\mathbf{w})}{\partial a}$.

state s → Policy Network (Parameter: θ) → action a = π(s; θ) → Value Network (Parameter: w) → value q(s,a; w)