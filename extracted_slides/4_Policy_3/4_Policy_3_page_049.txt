Approximate Policy Gradient

Approximate policy gradient:

g(a_t) \approx \frac{\partial \ln \pi(a_t \vert s_t; \theta)}{\partial \theta} \cdot (r_t + \gamma \cdot v(s_{t+1}; \mathbf{w}) - v(s_t; \mathbf{w}))

Approximation to \mathbb{E}[U_t \vert s_t]

At time t, the critic evaluates how good s_t is.