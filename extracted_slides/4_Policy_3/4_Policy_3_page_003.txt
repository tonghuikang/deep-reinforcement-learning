Actor and Critic

• Policy network (actor): $\pi(a \vert s; \boldsymbol{\theta})$.

  • It is an approximation to the policy function, $\pi(a \vert s)$.

  • It controls the agent.

• Value network (critic): $v(s; \mathbf{w})$.

  • It is an approximation to the state-value function, $V_\pi(s)$.

  • It evaluates how good the state $s$ is.