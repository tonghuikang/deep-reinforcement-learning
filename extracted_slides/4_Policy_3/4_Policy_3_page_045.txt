Updating Value Network

TD learning: Encourage v(s_t; \mathbf{w}) to approach y_t

• TD error: \delta_t = v(s_t; \mathbf{w}) - y_t

• Gradient: \frac{\partial \delta_t^2 / 2}{\partial \mathbf{w}} = \delta_t \cdot \frac{\partial v(s_t; \mathbf{w})}{\partial \mathbf{w}}

• Update value network by gradient descent:

\mathbf{w} \leftarrow \mathbf{w} - \alpha \cdot \delta_t \cdot \frac{\partial v(s_t; \mathbf{w})}{\partial \mathbf{w}}