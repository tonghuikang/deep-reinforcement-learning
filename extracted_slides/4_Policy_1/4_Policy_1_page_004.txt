Policy Gradient

• Use policy network, $\pi(a \vert s; \boldsymbol{\theta})$, for controlling the agent.
• State-value function:
    $V_\pi(s) = \mathbb{E}_{A \sim \pi} [Q_\pi(s, A)]$
    
    $= \sum_a \pi(a \vert s; \boldsymbol{\theta}) \cdot Q_\pi(s, a)$.
• Policy gradient:
    $\frac{\partial V_\pi(s)}{\partial \boldsymbol{\theta}} = \mathbb{E}_{A \sim \pi} \left[\frac{\partial \ln \pi(A \vert s; \boldsymbol{\theta})}{\partial \boldsymbol{\theta}} \cdot Q_\pi(s, A)\right]$.