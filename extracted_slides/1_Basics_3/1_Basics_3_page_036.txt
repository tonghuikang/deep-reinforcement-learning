Calculate Policy Gradient

Policy Gradient: $\frac{\partial V(s;\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} = \mathbb{E}_{A \sim \pi(\cdot \vert s;\boldsymbol{\theta})} \left[\frac{\partial \log \pi(A \vert s,\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} \cdot Q_\pi(s, A)\right]$.

1. Randomly sample an action $\hat{a}$ according to $\pi(\cdot \vert s; \boldsymbol{\theta})$.

2. Calculate $\mathbf{g}(\hat{a}, \boldsymbol{\theta}) = \frac{\partial \log \pi(\hat{a} \vert s;\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} \cdot Q_\pi(s, \hat{a})$.

3. Use $\mathbf{g}(\hat{a}, \boldsymbol{\theta})$ as an approximation to the policy gradient $\frac{\partial V(s;\boldsymbol{\theta})}{\partial \boldsymbol{\theta}}$.