Calculate Policy Gradient

Policy Gradient: $\frac{\partial V(s;\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} = \mathbb{E}_{A \sim \pi(\cdot \vert s;\boldsymbol{\theta})} \left[\frac{\partial \log \pi(A \vert s,\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} \cdot Q_\pi(s, A)\right]$.

1. Randomly sample an action $\hat{a}$ according to $\pi(\cdot \vert s; \boldsymbol{\theta})$.

2. Calculate $\mathbf{g}(\hat{a}, \boldsymbol{\theta}) = \frac{\partial \log \pi(\hat{a} \vert s;\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} \cdot Q_\pi(s, \hat{a})$.

• By the definition of $\mathbf{g}$, $\mathbb{E}_A[\mathbf{g}(A, \boldsymbol{\theta})] = \frac{\partial V(s;\boldsymbol{\theta})}{\partial \boldsymbol{\theta}}$.

• $\mathbf{g}(\hat{a}, \boldsymbol{\theta})$ is an unbiased estimate of $\frac{\partial V(s;\boldsymbol{\theta})}{\partial \boldsymbol{\theta}}$.